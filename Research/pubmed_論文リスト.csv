pmid,title,pub_year,journal,authors,abstract,url,abstract_ja
40651009,Large language models in medical education: a comparative cross-platform evaluation in answering histological questions.,2025,Medical education online,"Mavrych Volodymyr, Yousef Einas M, Yaqinuddin Ahmed, Bolgova Olena","Large language models (LLMs) have shown promising capabilities across medical disciplines, yet their performance in basic medical sciences remains incompletely characterized. Medical histology, requiring factual knowledge and interpretative skills, provides a unique domain for evaluating AI capabilities in medical education. To evaluate and compare the performance of five current LLMs: GPT-4.1, Claude 3.7 Sonnet, Gemini 2.0 Flash, Copilot, and DeepSeek R1 on correctly answering medical histology multiple choice questions (MCQs). This cross-sectional comparative study used 200 USMLE-style histology MCQs across 20 topics. Each LLM completed all the questions in three separate attempts. Performance metrics included accuracy rates, test-retest reliability (ICC), and topic-specific analysis. Statistical analysis employed ANOVA with post-hoc Tukey's tests and two-way mixed ANOVA for system-topic interactions. All LLMs achieved exceptionally high accuracy (Mean 91.1%, SD 7.2). Gemini performed best (92.0%), followed by Claude (91.5%), Copilot (91.0%), GPT-4 (90.8%), and DeepSeek (90.3%), with no significant differences between systems (<i>p</i> > 0.05). Claude showed the highest reliability (ICC = 0.931), followed by GPT-4 (ICC = 0.882). Complete accuracy and reproducibility (100%) were detected in Histological Methods, Blood and Hemopoiesis, and Circulatory System, while Muscle tissue (76.0%) and Lymphoid System (84.7%) presented the greatest challenges. LLMs demonstrate exceptional accuracy and reliability in answering histological MCQs, significantly outperforming other medical disciplines. Minimal inter-system variability suggests technological maturity, though topic-specific challenges and reliability concerns indicate the continued need for human expertise. These findings reflect rapid AI advancement and identify histology as particularly suitable for AI-assisted medical education.<b>Clinical trial number</b>: The clinical trial number is not pertinent to this study as it does not involve medicinal products or therapeutic interventions.",https://pubmed.ncbi.nlm.nih.gov/40651009/,大規模な言語モデル（LLM）は、医学分野で有望な能力を示していますが、基本医療科学のパフォーマンスは不完全な特徴づけのままです。事実に基づいた知識と解釈スキルを必要とする医学組織学は、医学教育におけるAI能力を評価するためのユニークなドメインを提供します。5つの現在のLLMSのパフォーマンスを評価して比較するために、GPT-4.1、Claude 3.7 Sonnet、Gemini 2.0 Flash、Copilot、およびDeepseek R1の医療組織学の複数選択質問（MCQ）に正しく答えることで。この断面比較研究では、20のトピックにわたって200のUSMLEスタイルの組織学MCQを使用しました。各LLMは、3つの別々の試みですべての質問を完了しました。パフォーマンスメトリックには、精度率、テストと再テストの信頼性（ICC）、およびトピック固有の分析が含まれていました。統計分析では、システムトピック相互作用のために、事後のTukeyのテストと双方向の混合ANOVAを使用してANOVAを採用しました。すべてのLLMは非常に高い精度を達成しました（平均91.1％、SD 7.2）。Geminiは最高のパフォーマンス（92.0％）、続いてClaude（91.5％）、Copilot（91.0％）、GPT-4（90.8％）、およびDeepSeek（90.3％）が続きました。クロードは最高の信頼性（ICC = 0.931）を示し、続いてGPT-4（ICC = 0.882）が続きました。完全な精度と再現性（100％）が組織学的方法、血液とhemopoiesis、および循環系で検出されましたが、筋肉組織（76.0％）とリンパ系（84.7％）が最大の課題を提示しました。LLMSは、組織学的MCQに答える際に例外的な精度と信頼性を示し、他の医療分野を大幅に上回っています。最小限のシステム間変動は技術の成熟度を示唆していますが、トピック固有の課題と信頼性の懸念は、人間の専門知識の継続的な必要性を示しています。これらの発見は、迅速なAIの進歩を反映し、AI支援医学教育に特に適した組織学を特定します。<b>臨床試験数</b>：臨床試験数は、薬物や治療的介入が含まれないため、この研究に関係していません。
40442891,Leveraging large language models for preoperative prevention of cardiopulmonary bypass-associated acute kidney injury.,2025,Renal failure,"Wang Kai, Lin Ling, Zheng Rui, Nan Shan, Lu Xudong, Duan Huilong","Acute kidney injury (AKI) usually occurs after cardiopulmonary bypass (CPB) and threatens life without timely intervention. Early assessment and prevention are critical for saving AKI patients. However, numerical data-driven models make it difficult to predict the AKI risk using preoperative data and lack preventive measures. Large language models (LLM) have demonstrated significant potential for medical decision-making, offering a promising approach. For preoperative assessment and prevention of CPB-associated AKI (CPB-AKI). Clinical variables were converted into text through prompt engineering and a LLM was used to extract information hidden in the semantics of subtle changes. A multimodal fusion model, fuzing semantic and numerical information, was proposed to assess the AKI risk before surgery. We then used a structural equation model to analyze the impact of preoperative features and intraoperative interventions on CPB-AKI prevention. A total of 2,056 patients who underwent CPB were enrolled from the intensive care unit of Sir Run Run Shaw Hospital between 2014 and 2022, with 40.5% progressing to AKI. Our model performed better with an area under the receiver operating characteristic curve of 0.9201 compared with the baseline models. The structural equation model's chi-square to degrees of freedom ratio was 0.46, less than 2.0. We discussed how the preoperative prediction model could optimize intraoperative interventions to prevent CPB-AKI. The prediction model can predict CPB-AKI risk earlier after fuzing the clinical characteristics and their semantics. Preoperative assessment and intraoperative interventions provide decision-making to prevent CPB-AKI.",https://pubmed.ncbi.nlm.nih.gov/40442891/,"急性腎障害（AKI）は通常、心肺バイパス（CPB）の後に発生し、タイムリーな介入なしに生命を脅かします。早期評価と予防は、AKI患者を救うために重要です。ただし、数値データ駆動型モデルにより、術前のデータを使用してAKIリスクを予測し、予防策がないことを困難にします。大規模な言語モデル（LLM）は、医学的意思決定の重要な可能性を実証しており、有望なアプローチを提供しています。CPB関連AKI（CPB-AKI）の術前評価と予防のため。臨床変数は迅速なエンジニアリングを通じてテキストに変換され、LLMを使用して微妙な変化のセマンティクスに隠された情報を抽出しました。手術前のAKIリスクを評価するために、セマンティックおよび数値情報を融合させるマルチモーダル融合モデルが提案されました。次に、構造方程式モデルを使用して、CPB-AKI予防に対する術前の特徴と術中介入の影響を分析しました。CPBを受けた合計2,056人の患者が、2014年から2022年にかけてサーランランショー病院の集中治療室から登録され、40.5％がAKIに進行しました。私たちのモデルは、ベースラインモデルと比較して、0.9201の受信機動作特性曲線の下の面積でより良くパフォーマンスを発揮しました。構造方程式モデルのカイ二乗と自由度比率は0.46で、2.0未満でした。術前予測モデルがCPB-AKIを防ぐために術中介入を最適化する方法について説明しました。予測モデルは、臨床的特性とそのセマンティクスを燃焼させた後、CPB-AKIリスクを早期に予測できます。術前評価と術中介入は、CPB-AKIを防ぐための意思決定を提供します。"
40689366,Toward Real-time Detection of Drug-induced Liver Injury Using Large Language Models: A Feasibility Study From Clinical Notes.,2025,Journal of clinical and experimental hepatology,"Suenghataiphorn Thanathip, Danpanichkul Pojsakorn, Tribuddharat Narisara, Kulthamrongsri Narathorn","Drug-induced liver injury (DILI) is a significant clinical problem. Current detection methods are often delayed. Real-time analysis of electronic medical records (EMRs) using a large language model (LLM) could enable earlier surveillance. To evaluate the technical feasibility of an LLM-powered system for real-time DILI identification assessment by extracting medication information from unstructured clinical notes. We developed a system using a large language model (LLM) to extract medication lists from clinical text. Prompts were iteratively refined for optimal performance. We integrated DILI risk data from DILIrank and LiverTox, utilizing LLM and algorithmic matching to link extracted medications to database entries. We utilized the RxNORM database and manual mistyped medication, as well as the NHANES database for a structured medication list, to verify accurate results. Using 30 entries each from NHANES, RxNORM, and real-world cases, the LLM-based medication extraction achieved a precision of 0.96, recall of 0.97, and an F1-score of 0.97%. For NHANES data, no errors were found. Applying to real-world cases and mistyped dataset, the LLM-based extraction fared acceptably, with F1-scores of 0.94 and 0.97, respectively. The majority of error are due to trade name and combined medication names. This study demonstrates the potential of LLMs for accurate medication extraction from clinical notes, a crucial step towards real-time DILI risk assessment. However, the system requires further development and clinical validation before implementation. Future work will focus on matching methods, clinical validation, EMR integration, and development of an agentic AI to triage future DILI risk.",https://pubmed.ncbi.nlm.nih.gov/40689366/,薬物誘発性肝障害（DILI）は重大な臨床的問題です。多くの場合、現在の検出方法が遅延します。大規模な言語モデル（LLM）を使用した電子医療記録（EMR）のリアルタイム分析は、早期の監視を可能にする可能性があります。構造化されていない臨床ノートから投薬情報を抽出することにより、リアルタイムのDILI識別評価のためのLLM駆動システムの技術的実現可能性を評価する。大規模な言語モデル（LLM）を使用してシステムを開発し、臨床テキストから薬物リストを抽出しました。プロンプトは、最適なパフォーマンスのために繰り返し洗練されていました。LLMとアルゴリズムのマッチングを利用して、抽出された薬をデータベースエントリにリンクするために、DilirankおよびLivertoxのDILIリスクデータを統合しました。正確な結果を確認するために、RXNORMデータベースと手動の誤った薬物、および構造化された薬物リストのNHANESデータベースを利用しました。NHANES、RXNORM、および実際のワールドのケースからそれぞれ30のエントリを使用して、LLMベースの薬抽出は0.96の精度、0.97、F1スコア0.97％のリコールを達成しました。NHANESデータの場合、エラーは見つかりませんでした。現実世界のケースと誤ったデータセットに適用すると、LLMベースの抽出はそれぞれ0.94と0.97のF1スコアで、許容範囲で実行されました。エラーの大部分は、商品名と薬の名前を組み合わせたものです。この研究は、臨床ノートからの正確な薬物抽出のためのLLMSの可能性を示しています。これは、リアルタイムのDILIリスク評価に向けた重要なステップです。ただし、このシステムには、実装前にさらなる開発と臨床検証が必要です。将来の作業では、一致方法、臨床検証、EMR統合、および将来のDILIリスクをトリアージするためのエージェントAIの開発に焦点を当てます。
40689255,"OpenAI o1 Large Language Model Outperforms GPT-4o, Gemini 1.5 Flash, and Human Test Takers on Ophthalmology Board-Style Questions.",2025,Ophthalmology science,"Shean Ryan, Shah Tathya, Sobhani Sina, Tang Alan, Setayesh Ali, Bolo Kyle, Nguyen Van, Xu Benjamin","To evaluate and compare the performance of human test takers and three artificial intelligence (AI) models-OpenAI o1, ChatGPT-4o, and Gemini 1.5 Flash-on ophthalmology board-style questions, focusing on overall accuracy and performance stratified by ophthalmic subspecialty and cognitive complexity level. A cross-sectional study. Five hundred questions sourced from the <i>Basic and Clinical Science Course (BCSC)</i> and <i>EyeQuiz</i> question banks. Three large language models interpreted the questions using standardized prompting procedures. Subanalysis was performed, stratifying the questions by subspecialty and complexity defined by the Buckwalter taxonomic schema. Statistical analysis, including the analysis of variance and McNemar test, was conducted to assess performance differences. Accuracy of responses for each model and human test takers, stratified by subspecialty and cognitive complexity. OpenAI o1 achieved the highest overall accuracy (423/500, 84.6%), significantly outperforming GPT-4o (331/500, 66.2%; <i>P</i> < 0.001) and Gemini (301/500, 60.2%; <i>P</i> < 0.001). o1 demonstrated superior performance on both <i>BCSC</i> (228/250, 91.2%) and <i>EyeQuiz</i> (195/250, 78.0%) questions compared with GPT-4o (<i>BCSC</i>: 183/250, 73.2%; <i>EyeQuiz</i>: 148/250, 59.2%) and Gemini (<i>BCSC</i>: 163/250, 65.2%; <i>EyeQuiz</i>: 137/250, 54.8%). On <i>BCSC</i> questions, human performance was lower (64.5%) than Gemini 1.5 Flash (65.2%), GPT-4o (73.2%), and OpenAI o1 (91.2%) (<i>P</i> < 0.001). OpenAI o1 outperformed other models in each of the nine ophthalmic subfields and three cognitive complexity levels. OpenAI o1 outperformed GPT-4o, Gemini, and human test takers in answering ophthalmology board-style questions from two question banks and across three complexity levels. These findings highlight advances in AI technology and OpenAI o1's growing potential as an adjunct in ophthalmic education and care. The author(s) have no proprietary or commercial interest in any materials discussed in this article.",https://pubmed.ncbi.nlm.nih.gov/40689255/,人間のテストテイカーと3つの人工知能（AI）モデル-openai O1、ChatGPT-4O、およびGemini 1.5 Flash-on Ophthalmologyボードスタイルの質問のパフォーマンスを評価して比較し、全体的な精度とパフォーマンスに焦点を当て、眼科下亜専門性と認知的複雑さレベルによって層別化されました。横断的研究。<i> Basic and Clinical Scienceコース（BCSC）</i>および<i> Eyequiz </i>からの500の質問。3つの大規模な言語モデルは、標準化されたプロンプト手順を使用して質問を解釈しました。サブ分析が行われ、Buckwalterの分類スキーマによって定義された下位専門性と複雑さによって質問を層別化しました。パフォーマンスの違いを評価するために、分散分析とMcNemarテストを含む統計分析が実施されました。亜専門性と認知的複雑さによって層別化された各モデルおよび人間のテスト者の応答の精度。Openai O1は、全体的な精度（423/500、84.6％）を達成し、GPT-4O（331/500、66.2％; <i> p </i> <0.001）およびジェミニ（301/500、60.2％; <i> p </i> <0.001）を大幅に上回っています。O1は、GPT-4O（<i>：183/250、78.0％）の質問と比較して、BCSC </i>（228/250、91.2％）および<i> Eyequiz </i>（195/250、78.0％）の両方で優れたパフォーマンスを示しました。（<i> bcsc </i>：163/250、65.2％; <i> eyequiz </i>：137/250、54.8％）。<i> bcsc </i>の質問では、Gemini 1.5 Flash（65.2％）、GPT-4o（73.2％）、およびOpenai O1（91.2％）（<i> p </i> <0.001）よりも人間のパフォーマンスが低かった（64.5％）。Openai O1は、9つの眼科サブフィールドと3つの認知複雑度レベルのそれぞれで他のモデルよりも優れていました。Openai O1は、2つの質問銀行と3つの複雑さレベルにわたって眼科ボードスタイルの質問に答える際に、GPT-4O、ジェミニ、および人間のテストテイカーを上回りました。これらの調査結果は、AIテクノロジーの進歩とOpenAI O1の眼科教育とケアの補助としての可能性の高まりを強調しています。著者は、この記事で議論されている資料に対して独自または商業的関心を持っていません。
40617017,Comparing the accuracy of large language models and prompt engineering in diagnosing realworld cases.,2025,International journal of medical informatics,"Yao Guanhong, Zhang WuJi, Zhu Yingxi, Wong Ut-Kei, Zhang Yanfeng, Yang Cui, Shen Guanghao, Li Zhanguo, Gao Hui","Large language models (LLMs) hold potential in clinical decision-making, especially for complex and rare disease diagnoses. However, real-world applications require further evaluation for accuracy and utility. To evaluate the diagnostic performance of four LLMs (GPT-4o mini, GPT-4o, ERNIE, and Llama-3) using real-world inpatient medical records and assess the impact of different prompt engineering methods. This single-center, retrospective study was conducted at Peking University International Hospital. It involved 1,122 medical records categorized into common rheumatic autoimmune diseases, rare rheumatic autoimmune diseases, and non-rheumatic diseases. Four LLMs were evaluated using two prompt engineering methods: few-shot and chain-of-thought prompting. Diagnostic accuracy (hit1) was defined as the inclusion of the first final diagnosis from the medical record in the model's top prediction. Hit1 of four LLMs were as follows: GPT-4omini (81.8 %), GPT-4o (82.4 %), ERNIE (82.9 %) and Llama-3 (82.7 %). Few-shot prompting significantly improved GPT-4o's hit1 (85.9 %) compared to its base model (p = 0.02), outperforming other models (all p < 0.05). Chain-of-thought prompting showed no significant improvement. Hit1 for both common and rare rheumatic diseases was consistently higher than that for non-rheumatic disease. Few-shot prompting increased costs per correct diagnosis for GPT-4o by approximately ¥4.54. LLMs, including GPT-4o, demonstrate promising diagnostic accuracy on real medical records. Few-shot prompting enhances performance but at higher costs, underscoring the need for accuracy improvements and cost management. These findings inform LLM development in Chinese medical contexts and highlight the necessity for further multi-center validation.",https://pubmed.ncbi.nlm.nih.gov/40617017/,"大規模な言語モデル（LLMS）は、特に複雑でまれな疾患診断のために、臨床的意思決定において可能性を秘めています。ただし、実際のアプリケーションでは、精度とユーティリティのさらなる評価が必要です。実際の入院患者の医療記録を使用して、4つのLLMS（GPT-4O MINI、GPT-4O、ERNIE、およびLLAMA-3）の診断パフォーマンスを評価し、さまざまな迅速なエンジニアリング方法の影響を評価します。この単一中心の遡及的研究は、北京大学国際病院で実施されました。一般的なリウマチ自己免疫疾患、まれなリウマチ自己免疫疾患、および非重症疾患に分類された1,122の医療記録が含まれていました。2つの迅速なエンジニアリング方法を使用して、4つのLLMを評価しました。診断精度（HIT1）は、モデルの最上位予測における医療記録からの最初の最終診断を含めることとして定義されました。4つのLLMのHIT1は次のとおりでした：GPT-4OMINI（81.8％）、GPT-4O（82.4％）、Ernie（82.9％）、Llama-3（82.7％）。いくつかのショットプロンプトで、GPT-4OのHIT1（85.9％）が基本モデル（P = 0.02）と比較して大幅に改善され、他のモデル（すべてP <0.05）を上回りました。考え方のプロンプトは、有意な改善を示しませんでした。一般的なリウマチ性疾患とまれなリウマチ性疾患の両方のHIT1は、非重症疾患のそれよりも一貫して高かった。GPT-4oの正しい診断ごとにコストの増加を促す少数のショット4.54°。GPT-4Oを含むLLMは、実際の医療記録で有望な診断精度を示しています。少数のショットプロンプトはパフォーマンスを向上させますが、より高いコストで、精度の向上とコスト管理の必要性を強調します。これらの調査結果は、中国の医療の文脈におけるLLM開発に情報を提供し、さらなるマルチセンター検証の必要性を強調しています。"
40581100,MDD-LLM: Towards accuracy large language models for major depressive disorder diagnosis.,2025,Journal of affective disorders,"Sha Yuyang, Pan Hongxin, Xu Wei, Meng Weiyu, Luo Gang, Du Xinyu, Zhai Xiaobing, Tong Henry H Y, Shi Caijuan, Li Kefeng","Major depressive disorder (MDD) impacts >300 million individuals worldwide, highlighting a significant public health issue. However, the uneven distribution of medical resources and the complexity of diagnostic methods have resulted in inadequate attention to this disorder in numerous countries and regions. This paper introduces a high-performance MDD diagnosis tool named MDD-LLM, an AI-driven framework that utilizes fine-tuned large language models (LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis. Specifically, we select 274,348 individual records from the UK Biobank cohort and design three tabular data transformation methods to create a large corpus for training and evaluating the proposed method. To illustrate the advantages of MDD-LLM, we perform comprehensive experiments and provide several comparative analyses against existing model-based solutions across multiple evaluation metrics. Experimental results show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of 0.8919 (95 % CI: 0.8799-0.9040), significantly outperforming existing machine and deep learning frameworks for MDD diagnosis. Given the limited exploration of LLMs in MDD diagnosis, we examine numerous factors that may influence the performance of our proposed method, including tabular data transformation techniques and different fine-tuning strategies. Furthermore, we also analyze the model's interpretability, requiring the MDD-LLM to explain its predictions and provide corresponding reasons. This paper investigates the application of LLMs and large-scale training samples for diagnosing MDD. The findings indicate that LLMs-driven schemes offer significant potential for accuracy, robustness, and interpretability in MDD diagnosis compared to traditional model-based solutions.",https://pubmed.ncbi.nlm.nih.gov/40581100/,"主要な抑うつ障害（MDD）は、世界中の3億人以上の個人に影響を与え、重大な公衆衛生問題を強調しています。しかし、医療資源の不均一な分布と診断方法の複雑さは、多くの国や地域でこの障害に不十分な注意を払っています。このペーパーでは、MDD-LLMという名前の高性能MDD診断ツールを紹介します。MDD-LLMは、MDD診断の課題に取り組むために微調整された大規模な言語モデル（LLM）と広範な現実世界のサンプルを利用するAI駆動型フレームワークです。具体的には、英国のBiobankコホートから274,348個の個別レコードを選択し、3つの表形式データ変換方法を設計して、提案された方法をトレーニングおよび評価するための大きなコーパスを作成します。MDD-LLMの利点を説明するために、包括的な実験を実行し、複数の評価メトリックにわたって既存のモデルベースのソリューションに対するいくつかの比較分析を提供します。実験結果は、MDD-LLM（70B）が0.8378の精度と0.8919（95％CI：0.8799-0.9040）のAUCを達成し、MDD診断のための既存のマシンと深い学習フレームワークを大幅に上回ることを示しています。MDD診断におけるLLMの調査が限られていることを考えると、表形式のデータ変換技術やさまざまな微調整戦略など、提案された方法のパフォーマンスに影響を与える可能性のある多くの要因を調べます。さらに、モデルの解釈可能性も分析し、MDD-LLMがその予測を説明し、対応する理由を提供する必要があります。このペーパーでは、MDDを診断するためのLLMSおよび大規模なトレーニングサンプルの適用を調査します。調査結果は、LLMS駆動型スキームが、従来のモデルベースのソリューションと比較して、MDD診断における精度、堅牢性、および解釈性の重大な可能性を提供することを示しています。"
40479778,Development and evaluation of a retrieval-augmented large language model framework for enhancing endodontic education.,2025,International journal of medical informatics,"Xu Xiaowei, Liu Siyi, Zhu Lin, Long Yunzi, Zeng Yin, Lu Xudong, Li Jiao, Dong Yanmei","Integrating domain-specific knowledge into large language models (LLMs) remains a critical challenge in medical education. In dental specialties such as endodontics, effective learning requires access to both textual clinical evidence and visual procedural demonstrations. However, generic LLMs often produce content that lacks clinical accuracy, contextual grounding, or pedagogical clarity, thereby limiting their applicability in specialized training environments. To develop and evaluate a Retrieval-Augmented Generation (RAG)-enhanced LLMs framework that addresses the challenge of integrating domain-specific knowledge in AI-driven endodontic education. We present Endodontics-KB, a multimodal knowledge integration platform that combines evidence-based dental literature (e.g., textbooks, clinical guidelines) with visual instructional materials (e.g., procedural videos) through a hierarchical RAG architecture. The system's core component, the EndoQ chatbot, utilizes LLMs augmented with multimodal dental datasets to enable context-aware clinical reasoning. Benchmarking was conducted against three general-purpose LLMs: GPT-4, Qwen2.5, and DeepSeek R1, using a structured question bank comprising 11 expert-validated endodontic questions. Two domain experts performed a blinded evaluation across five performance dimensions: clinical accuracy, contextual relevance, completeness, decision-making professionalism, and communication fluency. The framework integrated 2,200 multimodal knowledge units through dynamic semantic indexing. EndoQ demonstrated statistically significant improvements across all evaluation metrics compared to general purpose LLMs: accuracy (4.45 ± 0.96), clinical relevance (4.59 ± 0.8), completeness (4.27 ± 0.83), professionalism judgment (4.45 ± 1.06), and language fluency (4.86 ± 0.47), as measured on a 5-point Likert scale. This proposed framework improves educational outcomes through precise and context-aware knowledge delivery. Furthermore, it represents a scalable and transferable model for AI-enhanced clinical training across medical specialties, significantly advancing competency-based pedagogy in dental education.",https://pubmed.ncbi.nlm.nih.gov/40479778/,"ドメイン固有の知識を大規模な言語モデル（LLM）に統合することは、医学教育における重要な課題のままです。歯内療法などの歯科専門分野では、効果的な学習には、テキストの臨床的証拠と視覚的な手続き上のデモの両方にアクセスする必要があります。ただし、一般的なLLMは、多くの場合、臨床的精度、コンテキストの接地、または教育学的な明確さを欠くコンテンツを生成し、それにより特殊なトレーニング環境での適用性を制限します。AI駆動型の歯内療法におけるドメイン固有の知識を統合するという課題に対処する、検索された生成（RAG）強化LLMSフレームワークを開発および評価する。階層的なラグアーキテクチャを通じて、エビデンスに基づいた歯科文献（教科書、臨床ガイドラインなど）と視覚的指導資料（手続き的ビデオなど）を組み合わせたマルチモーダルナレッジ統合プラットフォームであるEndodontics-KBを紹介します。システムのコアコンポーネントであるEndoq Chatbotは、マルチモーダルの歯科データセットで拡張されたLLMSを使用して、コンテキスト対応の臨床的推論を可能にします。ベンチマークは、11の専門家で検証された歯内療法の質問を含む構造化された質問銀行を使用して、GPT-4、QWEN2.5、およびDeepSeek R1の3つの汎用LLMに対して実施されました。2人のドメインの専門家が、臨床的精度、コンテキスト関連、完全性、意思決定プロフェッショナリズム、コミュニケーションの流encyの5つのパフォーマンスの側面にわたって盲目的な評価を行いました。このフレームワークは、動的セマンティックインデックスを介して2,200マルチモーダルナレッジユニットを統合しました。ENDOQは、一般的な目的LLMS：精度（4.45±0.96）、臨床的関連（4.59±0.8）、完全性（4.27±0.83）、プロフェッショナリズムの判断（4.45±1.06）、言語の流fluency（4.86±0.47）、5ポイントの尺度としての尺度としての尺度（4.45±1.06）、および5ポイントの尺度としての統計的に有意な改善を実証しました。この提案されたフレームワークは、正確かつコンテキストを意識した知識提供を通じて教育成果を改善します。さらに、それは、医療専門分野全体でAIを強化した臨床トレーニングのためのスケーラブルで移転可能なモデルを表し、歯科教育におけるコンピテンシーベースの教育学を大幅に進めています。"
40706107,LLM-based approaches for automated vocabulary mapping between SIGTAP and OMOP CDM concepts.,2025,Artificial intelligence in medicine,"de Barros Vanzin Vinícius João, de Abreu Moreira Dilvan, Marcondes Marcacini Ricardo","In the context of global healthcare systems, integrating diverse medical terminologies and classification systems has become a priority due to the adoption of Electronic Health Record (EHR) systems and the imperative for information exchange between healthcare systems. This study addresses the necessity for mapping between the SIGTAP vocabulary used in Brazilian healthcare systems and the broader medical terms of the OMOP CDM terminologies. Two distinct pipelines are evaluated for the vocabulary mapping process, focusing on two subsets of the SIGTAP vocabulary: medicines and medical procedures. The first pipeline utilizes textual embeddings for semantic similarity evaluation, followed by Large Language Models (LLMs) for correspondences selection through a retrieval-augmented generation (RAG) approach. In the second pipeline, LLM agents employ predefined protocols for vocabulary mapping and query refinement. Our results show comparable performance between pipelines in both the Procedures subset (F<sub>1</sub> of 0.684 versus 0.678), and the Medicines subset (F<sub>1</sub> of 0.846 versus 0.839), indicating the viability of the multi-stage filtering approach. The second pipeline demonstrates an advantage over the first in terms of recall, highlighting the efficacy of dynamic query refinement by the agent. These findings provide evidence that LLM-based methods significantly reduce manual effort required by experts, enabling domain specialists to focus on more challenging cases.",https://pubmed.ncbi.nlm.nih.gov/40706107/,グローバルヘルスケアシステムのコンテキストでは、電子健康記録（EHR）システムの採用とヘルスケアシステム間の情報交換の命令により、多様な医療用語と分類システムを統合することが優先事項になりました。この研究では、ブラジルのヘルスケアシステムで使用されるSIGTAP語彙とOMOP CDM用語のより広範な医療条件との間のマッピングの必要性に取り組んでいます。語彙マッピングプロセスについては、2つの異なるパイプラインが評価され、SigTap語彙の2つのサブセット、医薬品と医療処置に焦点を当てています。最初のパイプラインは、セマンティックな類似性評価にテキスト埋め込みを利用し、その後、検索された生成（RAG）アプローチを介した対応選択のための大規模な言語モデル（LLMS）が続きます。2番目のパイプラインでは、LLMエージェントは語彙マッピングとクエリの改良のために事前定義されたプロトコルを採用しています。私たちの結果は、プロシージャサブセット（0.684対0.678のF <<sub> 1 </sub>）と、医薬品サブセット（0.846対0.839のF <sub> 1 </sub>）の両方のパイプライン間の同等のパフォーマンスを示しており、マルチステージフィルタリングアプローチの生存率を示しています。2番目のパイプラインは、エージェントによる動的クエリの改良の有効性を強調し、リコールの点で最初のパイプラインよりも利点を示しています。これらの調査結果は、LLMベースの方法が専門家が必要とする手動の努力を大幅に減らし、ドメインの専門家がより困難なケースに集中できるようにするという証拠を提供します。
40680485,Toward fair medical advice: Addressing and mitigating bias in large language model-based healthcare applications.,2025,Artificial intelligence in medicine,"Lu Haohui, Lin Ye, Li Zhidong, Yiu Man Lung, Gao Yu, Uddin Shahadat","Large Language Models (LLMs) are increasingly deployed in web-based medical advice applications, offering scalable and accessible healthcare solutions. However, their outputs often reflect demographic biases, raising concerns about fairness and equity for vulnerable populations. In this work, we propose FairMed, a framework designed to mitigate biases in LLM-generated medical advice through fine-tuning and prompt engineering strategies. We evaluate FairMed using language-based and content-level metrics across demographic groups on publicly available (MedQA), synthetic (Synthea), and private (CBHS) datasets. Experimental results demonstrate consistent improvements over Llama3 - Med42, as well as over the zero-shot prompting baseline. For instance, in sentiment analysis for gender groups using MedQA, FairMed with Descriptive Prompting reduces the Statistical Parity Difference (SPD) from 0.0902 to 0.0658, improves the Disparate Impact Ratio from 1.1916 to 1.1566, and decreases the Kullback-Leibler Divergence from 0.0045 to 0.0024. Similarly, in directive language evaluation for gender groups using Synthea, SPD improves from 0.1056 to nearly zero, achieving near-perfect parity. On the CBHS dataset, FairMed with Descriptive Prompting increases Diagnostic Recommendation Divergence (DRD) for race groups from 0.9530 to 0.9848, indicating improved group-specific tailoring, while reducing the Action Disparity Index (ADI) from 0.0857 to 0.0469 and Referral Frequency Parity (RFP) from 0.0791 to 0.0511, reflecting enhanced fairness. These findings highlight FairMed's effectiveness in addressing demographic disparities and promoting equitable healthcare guidance through web technologies. This framework contributes to building trustworthy and inclusive systems for delivering medical advice by ensuring fairness in sensitive applications.",https://pubmed.ncbi.nlm.nih.gov/40680485/,大規模な言語モデル（LLM）は、Webベースの医療アドバイスアプリケーションにますます展開されており、スケーラブルでアクセス可能なヘルスケアソリューションを提供しています。しかし、それらの生産量は多くの場合、人口統計学的偏見を反映しており、脆弱な集団の公平性と公平性に関する懸念を引き起こします。この作業では、微調整および迅速なエンジニアリング戦略を通じてLLM生成の医学的アドバイスのバイアスを緩和するように設計されたフレームワークであるFairmedを提案します。公開されている（MEDQA）、合成（シンセア）、およびプライベート（CBHS）データセットで、人口統計グループ全体で言語ベースとコンテンツレベルのメトリックを使用してフェアメッドを評価します。実験結果は、llama3 -med42およびゼロショットプロンプトベースラインよりも一貫した改善を示しています。たとえば、MEDQAを使用した性別グループの感情分析では、記述プロンプトでフェアメッドで統計的パリティの差（SPD）が0.0902から0.0658に減少し、異なる衝撃比を1.1916から1.1566に改善し、0.0045から0.0024から0.0045から0.0045から0.0045から0.0045への分岐を減少させます。同様に、Syntheaを使用した性別グループの指令言語評価では、SPDは0.1056からほぼゼロに向上し、ほぼ完璧なパリティを達成します。CBHSデータセットでは、記述プロンプトが0.9530から0.9848のレースグループの診断推奨の発散（DRD）を増加させ、グループ固有の仕立ての改善を示しながら、0.0857から0.0469から0.0469から0.0469から0.0791からの参照頻度（RFP）を反映した頻度（RFP）を削減することを示しています。これらの調査結果は、人口統計学的格差に対処し、Webテクノロジーを通じて公平なヘルスケアガイダンスを促進する際のFairmedの有効性を強調しています。このフレームワークは、デリケートなアプリケーションの公平性を確保することにより、医学的アドバイスを提供するための信頼できる包括的なシステムを構築することに貢献します。
40633400,From segmentation to explanation: Generating textual reports from MRI with LLMs.,2025,Computer methods and programs in biomedicine,"Valerio Alberto G, Trufanova Katya, de Benedictis Salvatore, Vessio Gennaro, Castellano Giovanna","Artificial Intelligence (AI) has significantly advanced medical imaging, yet the opacity of deep learning models remains challenging, often reducing the trust of medical professionals towards AI-driven diagnoses. As a result, there is a strong focus on making AI models more transparent and interpretable to boost healthcare providers' confidence in these technologies. This paper introduces a novel approach to enhance AI explainability in critical medical tasks by integrating state-of-the-art semantic segmentation models with atlas-based mapping and Large Language Models (LLMs) to produce comprehensive, human-readable medical reports. The proposed framework ensures that the generated outputs are factual and contextually rich. Our anti-hallucination design, which combines structured JSON with prompt constraints, is a critical innovation compared to most naïve LLM report generation methods, thereby enhancing the transparency and interpretability of AI systems. Experimental results show that the SegResNet model achieves high segmentation accuracy, while LLMs (Gemma, Llama, and Mistral) demonstrate diverse strengths in generating explanatory reports. Numerous metrics have been employed to assess the quality and effectiveness of generated textual explanations, such as lexical diversity, readability, coherence, and information coverage. The method has been specifically tested for brain tumor detection in glioma, one of the most aggressive forms of cancer, and subsequently applied to multiple sclerosis lesion detection to further validate its generalizability across various medical imaging scenarios, thereby contributing to the trustworthiness of healthcare AI applications. The complete source code for implementing the framework and reproducing the results is publicly available, along with full pipeline examples demonstrating each step - from segmentation to report generation - at the following repository: https://github.com/albertovalerio/from-segmentation-to-explanation.",https://pubmed.ncbi.nlm.nih.gov/40633400/,人工知能（AI）は医療イメージングを大幅に進めていますが、深い学習モデルの不透明度は挑戦的なままであり、多くの場合、AI駆動型の診断に対する医療専門家の信頼を減らします。その結果、AIモデルをより透明で解釈し、これらの技術に対する医療提供者の信頼を高めることに重点を置いています。このペーパーでは、最先端のセマンティックセグメンテーションモデルをAtlasベースのマッピングと大規模な言語モデル（LLM）と包括的で人間の読み取り可能な医療報告書を作成することにより、重要な医療タスクのAIの説明可能性を高めるための新しいアプローチを紹介します。提案されたフレームワークは、生成された出力が事実に基づいており、文脈的に豊富であることを保証します。構造化されたJSONと迅速な制約を組み合わせた当社の耐性設計は、ほとんどのナイーブLLMレポート生成方法と比較して重要な革新であり、それによりAIシステムの透明性と解釈可能性を高めます。実験結果は、SegreSnetモデルが高いセグメンテーション精度を達成し、LLMS（Gemma、Llama、およびMistral）が説明レポートを生成する際に多様な強みを示していることを示しています。語彙の多様性、読みやすさ、コヒーレンス、情報カバレッジなど、生成されたテキストの説明の品質と有効性を評価するために、多くの指標が採用されています。この方法は、癌の最も攻撃的な形態の1つである神経膠腫における脳腫瘍検出について特異的にテストされており、その後、さまざまな医療イメージングシナリオにわたる一般化可能性をさらに検証するために多発性硬化症の病変検出に適用され、それによってヘルスケアAIアプリケーションの信頼性に貢献します。フレームワークを実装し、結果を再現するための完全なソースコードは、次のリポジトリで次のリポジトリで、セグメンテーションから生成までの各ステップを示す完全なパイプラインの例とともに、公開されています。
40515934,The Emergence of Applied Artificial Intelligence in the Realm of Value Based Musculoskeletal Care.,2025,Current reviews in musculoskeletal medicine,"Hunter Jefferson, Dentino Philippe, Jayakumar Prakash","To establish the state-of-the-art in applied artificial intelligence (A.I) related to value-based musculoskeletal health care. We performed a literature review of A.I applications in orthopaedics and contextualized these studies based on their alignment with allocative value, technical value, and personal value. We synthesized our findings using descriptive analysis and the Gartner Hype Cycle. 82% of research activity involving A.I and its applications in musculoskeletal care is dominantly focused on technical value, which can be divided into three main sub-groups: imaging and diagnostics, prognostic outcomes and risk factors, and A.I integration within medical devices and care pathways. A.I advancing personal value (18% of studies) is rapidly gaining traction. Relatively few studies (< 1%) focused on allocative value. Emerging applications of A.I in orthopaedics providing 'technical value' include machine learning algorithms for predicting risk and prognosis, diagnostic computer vision algorithms, models advancing surgical robotics; 'personal value' include ambient listening technology, A.I scribes, triage of clinical messages, patient engagement via LLM chatbots, pre-charting applications; and emotional intelligence. Application of these technologies to Gartner's Hype Cycle suggests big data analytics and robotic surgery applications are approaching the plateau of productivity while multiagent / autonomous systems, emotional intelligence, and AI-enabled decision intelligence serve as innovation triggers but are in their infancy. A.I offers the opportunity to improve medical diagnosis, processes, practices and patient experiences and outcomes within musculoskeletal care delivery. While applications enhancing technical value and personal value are being actively researched and rapidly developed in the digital health industry, studies on how A.I provides value through equitable and fair allocation of resources at a population level should be promoted.",https://pubmed.ncbi.nlm.nih.gov/40515934/,価値ベースの筋骨格ヘルスケアに関連する適用された人工知能（A.I）の最先端を確立する。整形外科のA.Iアプリケーションの文献レビューを実行し、配分価値、技術的価値、および個人的価値との調整に基づいて、これらの研究を文脈化しました。記述分析とGartnerの誇大広告サイクルを使用して、調査結果を合成しました。A.Iに関与する研究活動の82％と筋骨格ケアへのその応用は、技術的価値に支配的に焦点を当てており、3つの主要なサブグループに分けることができます：イメージングと診断、予後的結果とリスク要因、および医療機器とケア経路内のA.I統合。A.I個人的価値（研究の18％）を前進させていることは、急速に牽引力を獲得しています。比較的少数の研究（<1％）が配分値に焦点を合わせました。「技術的価値」を提供する整形外科におけるA.Iの新たなアプリケーションには、リスクと予後を予測するための機械学習アルゴリズム、診断コンピュータービジョンアルゴリズム、外科的ロボット工学の前進モデルが含まれます。「個人的な価値」には、アンビエントリスニングテクノロジー、A.I筆記者、臨床メッセージのトリアージ、LLMチャットボットを介した患者の関与、事前に作成するアプリケーションが含まれます。と感情的な知性。これらの技術をガートナーの誇大広告サイクルに適用することは、ビッグデータ分析とロボット手術アプリケーションが生産性の高原に近づいていることを示唆していますが、マルチエージェント /自律システム、感情的知能、およびAI対応の意思決定インテリジェンスはイノベーショントリガーとして機能しますが、幼少期です。A.Iは、筋骨格ケアの提供における医療診断、プロセス、実践、患者の経験、および結果を改善する機会を提供します。技術的価値と個人的価値を高めるアプリケーションは、デジタルヘルス業界で積極的に研究され、急速に開発されていますが、A.Iは人口レベルでの公平かつ公正なリソースの割り当てを通じて価値を提供する方法についての研究を促進する必要があります。
40708759,Impact of prompting on large language model performance: ChatGPT-4 performance on the 2023 hand surgery self-assessment examination.,2025,Journal of hand and microsurgery,"Fiedler Benjamin, Barron Olivia A, Hauck Jeffrey, Scioscia Jacob, Phillips Todd, Ahmed Adil S, Mitchell Scott","Large language models (LLMs) such as ChatGPT are artificial intelligence programs designed to interpret and respond to text based input These programs can improve output based on prompting and tailored prompt engineering. Multiple studies have assessed the ability of various LLMs to perform on medical exams at different levels of training. The newest version of ChatGPT, GPT-4, allows image recognition which is relevant for many questions on orthopedic surgery exams. Performance of GPT-4, and the potential for LLMs to learn from prior exams remains unclear. The present study analyzed ChatGPT-4 performance on the 2023 hand surgery Maintenance of Certification (MOC) Self-Assessment Examination (SAE) before and after prompting with 5 previous versions of the test. It was hypothesized that GPT-4 would pass the exam and improve performance after prompting. GPT-4 was tested with all text and image-based questions from the 2023 hand surgery SAE. Video-based questions were excluded. GPT-4 was then provided with questions, answers, and explanations from 5 previous SAEs from 2014 to 2020 and retested on the 2023 SAE text and imaging questions. Responses from GPT-4 on prompted and unprompted tests were recorded and compared. Both prompted and unprompted versions of ChatGPT-4 exceeded SAE exam passing requirement of >50 % correct response rate. GPT-4 answered 67 % of all questions correctly unprompted and 71 % of all questions correctly after prompting (p = 0.51). Sub-analysis demonstrated GPT-4 answered 66 % of image-based questions correctly after prompting, compared to 56 % before prompting (p = 0.25). GPT-4 answered 75 % of text only questions correctly before prompting and 74 % correctly after prompting (p = 1.0). Fischer's exact test on total questions, image only, and text only showed no statistically significant differences between prompted and unprompted versions of GPT-4. GPT-4 demonstrated the ability to analyze orthopedic information, answer specialty-specific questions, and exceed the passing threshold of 50 % on the 2023 Hand Surgery Self-Assessment Exam. However, prompting GPT-4 with previous SAEs did not statistically significantly improve performance. With continued advancements in AI and deep learning, large language models may someday become resources in test simulation and knowledge checks in the realm of hand surgery.",https://pubmed.ncbi.nlm.nih.gov/40708759/,CHATGPTなどの大規模な言語モデル（LLM）は、テキストベースの入力を解釈して応答するように設計された人工知能プログラムです。これらのプログラムは、プロンプトとカスタマイズされたプロンプトエンジニアリングに基づいて出力を改善できます。複数の研究により、さまざまなLLMがさまざまなレベルのトレーニングで健康診断で実行する能力が評価されています。CHATGPTの最新バージョンであるGPT-4は、整形外科試験に関する多くの質問に関連する画像認識を可能にします。GPT-4のパフォーマンス、およびLLMSが以前の試験から学習する可能性は不明のままです。本研究では、5つの以前のバージョンのテストで促進する前後の2023年の手術維持認定（MOC）自己評価試験（SAE）のCHATGPT-4パフォーマンスを分析しました。GPT-4が試験に合格し、プロンプト後にパフォーマンスを改善すると仮定されました。GPT-4は、2023年の手術SAEからのすべてのテキストおよび画像ベースの質問でテストされました。ビデオベースの質問は除外されました。GPT-4には、2014年から2020年までの5つの以前のSAEからの質問、回答、説明が提供され、2023年のSAEテキストとイメージングの質問に再テストされました。プロンプトされたテストと未施設のテストに対するGPT-4からの応答が記録され、比較されました。CHATGPT-4のプロンプト化されていないバージョンと非採用バージョンの両方が、50％を超える正しい回答率のSAE試験の合格要件を超えました。GPT-4は、すべての質問の67％に、プロンプトをプロンプトした後に正しく採用されていない67％とすべての質問の71％に正しく答えました（p = 0.51）。サブ分析により、GPT-4は、プロンプト後の56％と比較して、プロンプト後に画像ベースの質問の66％に正しく答えました（p = 0.25）。GPT-4は、テキストの75％に、プロンプトを入力する前に正しく質問のみ、プロンプト（p = 1.0）後に74％に正しく質問しました。総質問、画像のみ、およびテキストに関するフィッシャーの正確なテストは、GPT-4のプロンプトバージョンと非プロンプトバージョンの間に統計的に有意な違いのみを示しませんでした。GPT-4は、整形外科情報を分析し、専門固有の質問に答え、2023年の手術自己評価試験で50％の通過しきい値を超える能力を実証しました。ただし、以前のSAEでGPT-4を促すことで、統計的にパフォーマンスが大幅に向上しませんでした。AIでの継続的な進歩と深い学習により、大規模な言語モデルは、いつかテストシミュレーションのリソースになり、手術の領域での知識チェックになる可能性があります。
40683982,Evaluation of a retrieval-augmented generation system using a Japanese Institutional Nuclear Medicine Manual and large language model-automated scoring.,2025,Radiological physics and technology,"Fukui Yusuke, Kawata Yuhei, Kobashi Kazumasa, Nagatani Yukihiro, Iguchi Harumi","Recent advances in large language models (LLMs) enable domain-specific question answering using external knowledge. However, addressing information that is not included in training data remains a challenge, particularly in nuclear medicine, where examination protocols are frequently updated and vary across institutions. In this study, we developed a retrieval-augmented generation (RAG) system using 40 internal manuals from a single Japanese hospital, each corresponding to a different examination in nuclear medicine. These institution-specific documents were segmented and indexed using a hybrid retrieval strategy combining dense vector search (text-embedding-3-small) and sparse keyword search (BM25). GPT-3.5 and GPT-4o were used with the OpenAI application programming interface (API) for response generation. The quality of the generated answers was assessed using a four-point Likert scale by three certified radiological technologists, of which one held an additional certification in nuclear medicine and another held an additional certification in medical physics. Automated evaluation was conducted using RAGAS metrics, including factual correctness and context recall. The GPT-4o model combined with hybrid retrieval achieved the highest performance, as per expert evaluations. Although traditional string-based metrics such as ROUGE and the Levenshtein distance poorly align with human ratings, RAGAS provided consistent rankings across system configurations, despite showing only a modest correlation with manual scores. These findings demonstrate that integrating examination-specific institutional manuals into RAG frameworks can effectively support domain-specific question answering in nuclear medicine. Moreover, LLM-based evaluation methods such as RAGAS may serve as practical tools to complement expert reviews in developing healthcare-oriented artificial intelligence systems.",https://pubmed.ncbi.nlm.nih.gov/40683982/,大規模な言語モデル（LLMS）の最近の進歩により、外部の知識を使用したドメイン固有の質問応答が可能になります。ただし、トレーニングデータに含まれていない情報への対処は、特に核医学では課題のままです。核医学では、検査プロトコルが頻繁に更新され、機関によって異なります。この研究では、核医学の異なる検査に対応する、単一の日本の病院から40の内部マニュアルを使用して、検索された生成（RAG）システムを開発しました。これらの機関固有のドキュメントは、高密度ベクトル検索（Text-rembedding-3-Small）とスパースキーワード検索（BM25）を組み合わせたハイブリッド検索戦略を使用してセグメント化およびインデックス作成されました。GPT-3.5およびGPT-4Oは、応答生成のためにOpenAIアプリケーションプログラミングインターフェイス（API）で使用されました。生成された回答の品質は、3人の認定放射線技術者による4点のリッカートスケールを使用して評価され、1人は核医学の追加認定を行い、もう1人は医学物理学の追加認定を保持しました。自動評価は、事実上の正確性とコンテキストリコールを含むRagasメトリックを使用して実施されました。GPT-4Oモデルとハイブリッド検索を組み合わせたものは、専門家の評価に従って、最高のパフォーマンスを達成しました。RougeやLevenshtein距離などの従来の文字列ベースのメトリックは、人間の評価とは不十分ですが、Ragasは、手動スコアとの控えめな相関のみを示しているにもかかわらず、システム構成全体で一貫したランキングを提供しました。これらの調査結果は、試験固有の組織マニュアルをRAGフレームワークに統合することで、核医学におけるドメイン固有の質問応答を効果的にサポートできることを示しています。さらに、RAGASなどのLLMベースの評価方法は、医療指向の人工知能システムの開発における専門家のレビューを補完するための実用的なツールとして機能する可能性があります。
40677929,Development and Evaluation of an Artificial Intelligence-Powered Surgical Oral Examination Simulator: A Pilot Study.,2025,Mayo Clinic proceedings. Digital health,"Rao Arya S, Prasad Siona, Lee Richard S, Farrell Susan, McKinley Sophia, Succi Marc D","To develop and validate an artificial intelligence-powered platform that simulates surgical oral examinations, addressing the limitations of traditional faculty-led sessions. This cross-sectional study, conducted from June 1, 2024, through December 1, 2024, comprised technical validation and educational assessment of a novel large language model (LLM)-based surgical education tool (surgery oral examination large language model [SOE-LLM]). The study involved 12 surgical clerkship students completing their core rotation at a major academic medical center. The SOE-LLM, using MIMIC-IV-derived surgical cases (acute appendicitis and pancreatitis), was implemented to simulate oral examinations. Technical validation assessed performance across 8 domains: case presentation accuracy, physical examination findings, historical detail preservation, laboratory data reporting, imaging interpretation, management decisions, and recognition of contraindicated interventions. Educational utility was evaluated using a 5-point Likert scale. Technical validation showed the SOE-LLM's ability to function as a consistent oral examiner. The model accurately guided students through case presentations, responded to diagnostic questions, and provided clinically sound responses based on MIMIC-IV cases. When tested with standardized prompts, it maintained examination fidelity, requiring proper diagnostic reasoning and differentiating operative versus medical management. Student evaluations highlighted the platform's value as an examination preparation tool (mean, 4.250; SEM, 0.1794) and its ability to create a low-stakes environment for high-stakes decision practice (mean, 4.833; SEM, 0.1124). The SOE-LLM shows potential as a valuable tool for surgical education, offering a consistent and accessible platform for simulating oral examinations.",https://pubmed.ncbi.nlm.nih.gov/40677929/,従来の教員主導のセッションの限界に対処するために、外科的経口検査をシミュレートする人工知能駆動のプラットフォームを開発および検証する。2024年6月1日から2024年12月1日までに実施されたこの横断的研究は、新しい大規模言語モデル（LLM）ベースの外科教育ツール（手術口頭検査大規模言語モデル[SOE-LLM]）の技術的検証と教育評価で構成されました。この研究には、主要なアカデミックメディカルセンターでコアローテーションを完了する12人の外科書記官が参加しました。SOE-LLMは、模倣IV由来の外科的症例（急性虫垂炎および膵炎）を使用して、口腔検査をシミュレートするために実装されました。技術的検証では、8つのドメインでパフォーマンスを評価しました：ケースプレゼンテーションの精度、身体検査の調査結果、歴史的詳細保存、実験室データの報告、イメージング解釈、管理の決定、および禁忌介入の認識。教育ユーティリティは、5ポイントのリッカートスケールを使用して評価されました。技術的検証により、SOE-LLMが一貫した口腔診察室として機能する能力が示されました。このモデルは、ケースプレゼンテーションを通じて学生を正確に導き、診断の質問に応答し、模倣IVの症例に基づいて臨床的に健全な反応を提供しました。標準化されたプロンプトでテストされた場合、適切な診断の推論を必要とし、手術と医療管理を区別する必要がありました。学生の評価により、プラットフォームの価値は、試験準備ツール（平均、4.250; SEM、0.1794）としての価値を強調しました。また、ハイステークスの決定実践のために低ステーク環境を作成する能力（平均、4.833; SEM、0.1124）を強調しました。SOE-LLMは、外科教育のための貴重なツールとしての可能性を示しており、口頭試験をシミュレートするための一貫したアクセス可能なプラットフォームを提供します。
40669284,Refining LLMs outputs with iterative consensus ensemble (ICE).,2025,Computers in biology and medicine,"Omar Mahmud, Glicksberg Benjamin S, Nadkarni Girish N, Klang Eyal","Large language models (LLMs) show promising accuracy on challenging tasks, including medical question answering. Yet, direct gains from model upgrades can plateau, and reliability issues persist. We introduce Iterative Consensus Ensemble (ICE), a proof-of-concept framework that refines answers through iterative reasoning and feedback among multiple LLMs. This ensemble method encourages diverse models to scrutinize each other's outputs, converging on a consensus solution. We tested ICE on four different datasets. These included over 4000 multiple-choice questions drawn from a newly curated primary care exam set, established medical benchmarks, and a PhD-level reasoning dataset. Compared to initial single-model attempts, ICE improved final overall accuracy by up to 27 %. It reached accuracies 81 % in medical subsets and 72 % in multi-domain tasks from initial scores of about 72 % and 60 %, respectively. In a particularly challenging PhD-level reasoning benchmark (GPQA-diamond), ICE raised performance from 46.9 % initially to 68.2 % at the final consensus, a relative gain exceeding 45 %. On a specialized family medicine dataset, ICE's results were statistically indistinguishable from those of a complex reasoning model (O1-preview), despite O1's higher cost and computational demands. Additional analyses showed that ICE's iterative consensus remained effective under different prompting styles. Our proposed framework leverages standard LLMs and repeated prompting, requiring no specialized reward models or intricate token-level fusion. These findings show that iterative collaboration can transform LLM ensembles into more reliable, cost-efficient solvers, advancing performance in medical and general reasoning domains. Future refinements may integrate chain-of-thought steps or specialist models, extending this approach to more complex challenges as LLMs and benchmarks continue to evolve.",https://pubmed.ncbi.nlm.nih.gov/40669284/,大規模な言語モデル（LLMS）は、医療質問の回答を含む、挑戦的なタスクの有望な正確性を示しています。しかし、モデルのアップグレードからの直接的な利益はプラトーになる可能性があり、信頼性の問題は持続します。複数のLLM間の反復推論とフィードバックを通じて回答を改良する概念実証フレームワークである反復コンセンサスアンサンブル（ICE）を紹介します。このアンサンブル方法は、多様なモデルが互いの出力を精査することを促進し、コンセンサスソリューションに収束します。4つの異なるデータセットでICEをテストしました。これらには、新たにキュレーションされたプライマリケア試験セット、確立された医療ベンチマーク、およびPHDレベルの推論データセットから描かれた4000以上の複数選択の質問が含まれていました。初期のシングルモデルの試みと比較して、ICEは最終的な全体的な精度を最大27％改善しました。医療サブセットでは、それぞれ約72％と60％の初期スコアからマルチドメインタスクで72％に達しました。特に挑戦的なPHDレベルの推論ベンチマーク（GPQA-ダイアモンド）では、ICEは最終コンセンサスで最初は46.9％から68.2％にパフォーマンスを上げました。専門化された家庭医学データセットでは、O1のより高いコストと計算の要求にもかかわらず、ICEの結果は複雑な推論モデル（O1-Preview）の結果と統計的に区別できませんでした。追加の分析により、ICEの反復コンセンサスは、さまざまなプロンプトスタイルの下で効果的なままであることが示されました。提案されたフレームワークは、標準のLLMと繰り返しプロンプトを活用し、専門的な報酬モデルや複雑なトークンレベルの融合を必要としません。これらの調査結果は、反復的なコラボレーションがLLMアンサンブルをより信頼性の高い費用効率の高いソルバーに変換し、医療および一般的な推論ドメインのパフォーマンスを進めることができることを示しています。将来の改良により、チェーンのステップまたは専門モデルが統合され、LLMSとベンチマークが進化し続けるにつれて、このアプローチをより複雑な課題に拡張することができます。
40614511,"Radiology report generation using automatic keyword adaptation, frequency-based multi-label classification and text-to-text large language models.",2025,Computers in biology and medicine,"He Zebang, Wong Alex Ngai Nick, Yoo Jung Sun","Radiology reports are essential in medical imaging, providing critical insights for diagnosis, treatment, and patient management by bridging the gap between radiologists and referring physicians. However, the manual generation of radiology reports is time-consuming and labor-intensive, leading to inefficiencies and delays in clinical workflows, particularly as case volumes increase. Although deep learning approaches have shown promise in automating radiology report generation, existing methods, particularly those based on the encoder-decoder framework, suffer from significant limitations. These include a lack of explainability due to black-box features generated by encoder and limited adaptability to diverse clinical settings. In this study, we address these challenges by proposing a novel deep learning framework for radiology report generation that enhances explainability, accuracy, and adaptability. Our approach replaces traditional black-box features in computer vision with transparent keyword lists, improving the interpretability of the feature extraction process. To generate these keyword lists, we apply a multi-label classification technique, which is further enhanced by an automatic keyword adaptation mechanism. This adaptation dynamically configures the multi-label classification to better adapt specific clinical environments, reducing the reliance on manually curated reference keyword lists and improving model adaptability across diverse datasets. We also introduce a frequency-based multi-label classification strategy to address the issue of keyword imbalance, ensuring that rare but clinically significant terms are accurately identified. Finally, we leverage a pre-trained text-to-text large language model (LLM) to generate human-like, clinically relevant radiology reports from the extracted keyword lists, ensuring linguistic quality and clinical coherence. We evaluate our method using two public datasets, IU-XRay and MIMIC-CXR, demonstrating superior performance over state-of-the-art methods. Our framework not only improves the accuracy and reliability of radiology report generation but also enhances the explainability of the process, fostering greater trust and adoption of AI-driven solutions in clinical practice. Comprehensive ablation studies confirm the robustness and effectiveness of each component, highlighting the significant contributions of our framework to advancing automated radiology reporting. In conclusion, we developed a novel deep-learning based radiology report generation method for preparing high-quality and explainable radiology report for chest X-ray images using the multi-label classification and a text-to-text large language model. Our method could address the lack of explainability in the current workflow and provide a clear and flexible automated pipeline to reduce the workload of radiologists and support the further applications related to Human-AI interactive communications.",https://pubmed.ncbi.nlm.nih.gov/40614511/,放射線科のレポートは、医療イメージングに不可欠であり、放射線科医と紹介医との間のギャップを埋めることにより、診断、治療、患者管理のための重要な洞察を提供します。ただし、放射線レポートの手動生成は時間がかかり、労働集約的であり、特に症例量が増加するにつれて、臨床ワークフローの非効率性と遅延につながります。深い学習アプローチは、放射線レポートの生成を自動化する際に有望であることが示されていますが、既存の方法、特にエンコーダデコーダーフレームワークに基づく方法は、大きな制限に苦しんでいます。これらには、エンコーダーによって生成されたブラックボックス機能による説明可能性の欠如と、多様な臨床設定への適応性が限られています。この研究では、説明可能性、精度、および適応性を高める放射線レポート生成のための新しい深い学習フレームワークを提案することにより、これらの課題に対処します。私たちのアプローチは、コンピュータービジョンの従来のブラックボックス機能を透明なキーワードリストに置き換え、機能抽出プロセスの解釈可能性を改善します。これらのキーワードリストを生成するために、マルチラベル分類手法を適用します。これは、自動キーワード適応メカニズムによってさらに強化されます。この適応は、マルチラベル分類を動的に構成して、特定の臨床環境をよりよく適合させ、手動でキュレーションされた参照キーワードリストへの依存を減らし、多様なデータセット全体でモデルの適応性を改善します。また、周波数ベースのマルチラベル分類戦略を導入して、キーワードの不均衡の問題に対処し、まれではあるが臨床的に有意な用語が正確に特定されるようにします。最後に、事前に訓練されたテキストからテキストへの大型言語モデル（LLM）を活用して、抽出されたキーワードリストから人間のような臨床的に関連する放射線レポートを生成し、言語の品質と臨床的一貫性を確保します。2つのパブリックデータセット、IU-XRAYとMIMIC-CXRを使用してメソッドを評価し、最新の方法よりも優れたパフォーマンスを実証します。私たちのフレームワークは、放射線レポートの生成の精度と信頼性を改善するだけでなく、プロセスの説明可能性を高め、臨床診療におけるAI駆動型ソリューションのより大きな信頼と採用を促進します。包括的なアブレーション研究は、各コンポーネントの堅牢性と有効性を確認し、自動放射線報告の進歩へのフレームワークの重要な貢献を強調しています。結論として、マルチラベル分類とテキストツーテキストの大手言語モデルを使用して、胸部X線画像の高品質で説明可能な放射線レポートを準備するための新しいディープラーニングベースの放射線レポート生成方法を開発しました。私たちの方法は、現在のワークフローにおける説明可能性の欠如に対処し、放射線科医のワークロードを減らし、人間とインタラクティブ通信に関連するさらなるアプリケーションをサポートするための明確で柔軟な自動化されたパイプラインを提供することができます。
40583928,Battle of the Bots: Solving Clinical Cases in Osteoarticular Infections With Large Language Models.,2025,Mayo Clinic proceedings. Digital health,"Borgonovo Fabio, Matsuo Takahiro, Petri Francesco, Amin Alavi Seyed Mohammad, Mazudie Ndjonko Laura Chelsea, Gori Andrea, Berbari Elie F","To evaluate the ability of 15 different large language models (LLMs) to solve clinical cases with osteoarticular infections following published guidelines. The study evaluated 15 LLMs across 5 categories of osteoarticular infections: periprosthetic joint infection, diabetic foot infection, native vertebral osteomyelitis, fracture-related infections, and septic arthritis. Models were selected systematically, including general-purpose and medical-specific systems, ensuring robust English support. In total, 126 text-based questions, developed by the authors from published guidelines and validated by experts, assessed diagnostic, management, and treatment strategies. Each model answered individually, with responses classified as correct or incorrect based on guidelines. All tests were conducted between April 17, 2025, and April 28, 2025. Results, presented as percentages of correct answers and aggregated scores, highlight performance trends. Mixed-effects logistic regression with a random question effect was used to quantify how each LLM compared in answering the study questions. The performance of 15 LLMs was evaluated, with the percentage of correct answers reported. OpenEvidence and Microsoft Copilot achieved the highest score (119/126 [94.4%]), excelling in multiple categories. ChatGPT-4o and Gemini 2.5 Pro scored 117 of the 126 (92.8%). When used as references, OpenEvidence was not inferior to any comparator and was superior to 5 LLMs. Performance varied across categories, highlighting the strengths and limitations of individual models. OpenEvidence and Miccrosoft Copilot achieved the highest accuracy among evaluated LLMs, highlighting their potential for precisely addressing complex clinical cases. This study emphasizes the need for specialized, validated artificial intelligence tools in medical practice. Although promising, current models face limitations in real-world applications, requiring further refinement to support clinical decision making reliably.",https://pubmed.ncbi.nlm.nih.gov/40583928/,15の異なる大手言語モデル（LLM）の能力を評価し、公開されたガイドラインに従って骨宮頭感染症の臨床症例を解決します。この研究では、骨膝頭感染の5つのカテゴリで15 LMSを評価しました。周囲の関節感染、糖尿病性足感染、天然脊椎骨髄炎、骨折関連の感染症、敗血症性関節炎。汎用や医療固有のシステムを含むモデルが体系的に選択され、堅牢な英語のサポートが確保されました。合計で、公開されたガイドラインから著者によって開発され、専門家によって検証された126のテキストベースの質問が、診断、管理、および治療戦略を評価しました。各モデルは個別に回答し、ガイドラインに基づいて正しいまたは正しくないと分類された応答がありました。すべてのテストは、2025年4月17日から2025年4月28日の間に実施されました。結果は、正解と集約されたスコアの割合として提示され、パフォーマンスの傾向を強調しています。ランダムな質問効果を備えた混合効果ロジスティック回帰を使用して、各LLMが研究の質問に答える際にどのように比較されるかを定量化しました。15 LLMのパフォーマンスが評価され、正解の割合が報告されました。OpenEvidenceとMicrosoft Copilotは、複数のカテゴリで優れている最高スコア（119/126 [94.4％]）を達成しました。ChatGpt-4oとGemini 2.5 Proは、126のうち117を獲得しました（92.8％）。参考文献として使用する場合、OpenEvidenceはComparatorよりも劣り、5 LLMよりも優れていました。パフォーマンスはカテゴリによって異なり、個々のモデルの強みと制限を強調しました。OpenEvidenceとMiccrosoft Copilotは、評価されたLLMSの間で最高の精度を達成し、複雑な臨床症例に正確に対処する可能性を強調しました。この研究では、医療行為において、専門的で検証された人工知能ツールの必要性が強調されています。有望ですが、現在のモデルは実際のアプリケーションの制限に直面しており、臨床的意思決定を確実にサポートするためにさらに洗練されています。
40554973,From BERT to generative AI - Comparing encoder-only vs. large language models in a cohort of lung cancer patients for named entity recognition in unstructured medical reports.,2025,Computers in biology and medicine,"Arzideh Kamyar, Schäfer Henning, Allende-Cid Héctor, Baldini Giulia, Hilser Thomas, Idrissi-Yaghir Ahmad, Laue Katharina, Chakraborty Nilesh, Doll Niclas, Antweiler Dario, Klug Katrin, Beck Niklas, Giesselbach Sven, Friedrich Christoph M, Nensa Felix, Schuler Martin, Hosch René","Extracting clinical entities from unstructured medical documents is critical for improving clinical decision support and documentation workflows. This study examines the performance of various encoder and decoder models trained for Named Entity Recognition (NER) of clinical parameters in pathology and radiology reports, highlighting the applicability of Large Language Models (LLMs) for this task. Three NER methods were evaluated: (1) flat NER using transformer-based models, (2) nested NER with a multi-task learning setup, and (3) instruction-based NER utilizing LLMs. A dataset of 2013 pathology reports and 413 radiology reports, annotated by medical students, was used for training and testing. The performance of encoder-based NER models (flat and nested) was superior to that of LLM-based approaches. The best-performing flat NER models achieved F1-scores of 0.87-0.88 on pathology reports and up to 0.78 on radiology reports, while nested NER models performed slightly lower. In contrast, multiple LLMs, despite achieving high precision, yielded significantly lower F1-scores (ranging from 0.18 to 0.30) due to poor recall. A contributing factor appears to be that these LLMs produce fewer but more accurate entities, suggesting they become overly conservative when generating outputs. LLMs in their current form are unsuitable for comprehensive entity extraction tasks in clinical domains, particularly when faced with a high number of entity types per document, though instructing them to return more entities in subsequent refinements may improve recall. Additionally, their computational overhead does not provide proportional performance gains. Encoder-based NER models, particularly those pre-trained on biomedical data, remain the preferred choice for extracting information from unstructured medical documents.",https://pubmed.ncbi.nlm.nih.gov/40554973/,非構造化された医療文書から臨床エンティティを抽出することは、臨床的意思決定サポートと文書化ワークフローを改善するために重要です。この研究では、病理学および放射線学レポートにおける臨床パラメーターの名前付きエンティティ認識（NER）のためにトレーニングされたさまざまなエンコーダーおよびデコーダーモデルのパフォーマンスを調べ、このタスクの大規模な言語モデル（LLMS）の適用性を強調しています。3つのNERメソッドが評価されました。（1）変圧器ベースのモデルを使用したフラットNER、（2）マルチタスク学習セットアップを備えたネストされたNER、および（3）LLMを利用する命令ベースのNER。2013年の病理学レポートと413の放射線レポートのデータセットは、医学生によって注釈が付けられ、トレーニングとテストに使用されました。エンコーダーベースのNERモデル（フラットおよびネストされた）のパフォーマンスは、LLMベースのアプローチのパフォーマンスよりも優れていました。最高のパフォーマンスのフラットNERモデルは、病理学レポートで0.87-0.88のF1スコアを達成し、放射線学レポートでは最大0.78を達成しましたが、ネストされたNERモデルはわずかに低いパフォーマンスを発揮しました。対照的に、複数のLLMは、高精度を達成したにもかかわらず、リコールが不十分なため、F1スコアが大幅に低く（0.18〜0.30の範囲）が得られました。貢献要因は、これらのLLMがより少ないが正確なエンティティを生成することであり、出力を生成するときに過度に保守的になることを示唆していることです。現在の形式のLLMSは、特にドキュメントごとに多数のエンティティタイプに直面している場合、臨床ドメインでの包括的なエンティティ抽出タスクには適していませんが、その後の改良点でより多くのエンティティを返すように指示すると、リコールが改善される可能性があります。さらに、計算オーバーヘッドは、比例パフォーマンスの向上を提供しません。エンコーダーベースのNERモデル、特に生物医学データで事前に訓練されたモデルは、構造化されていない医療文書から情報を抽出するための好ましい選択肢のままです。
40541074,Assessing large language models for acute heart failure classification and information extraction from French clinical notes.,2025,Computers in biology and medicine,"Bazoge Adrien, Wargny Matthieu, Constant Dit Beaufils Pacôme, Morin Emmanuel, Daille Béatrice, Gourraud Pierre-Antoine, Hadjadj Samy","Understanding acute heart failure (AHF) remains a significant challenge, as many clinical details are recorded in unstructured text rather than structured data in electronic health records (EHRs). In this study, we explored the use of large language models (LLMs) to automatically identify AHF hospitalizations and extract accurate AHF-related clinical information from clinical notes. Based on clinical notes from the Nantes University Hospital in France, we used a general-purpose LLM, Qwen2-7B, and evaluated its performance against a French biomedical pretrained model, DrLongformer. We explored supervised fine-tuning and in-context learning techniques, such as few-shot and chain-of-thought prompting, and performed an ablation study to analyze the impact of data volume and annotation characteristics on model performance. Our results demonstrated that DrLongformer achieved superior performance in classifying AHF hospitalizations, with an F1 score of 0.878 compared to 0.80 for Qwen2-7B, and similarly outperformed in extracting most of the clinical information. However, Qwen2-7B showed better performance in extracting quantitative outcomes when fine-tuned on the training set (typically weight and body mass index, for example). Our ablation study revealed that the number of clinical notes used in training is a significant factor influencing model performance, but improvements plateaued after 250 documents. Additionally, we observed that longer annotations negatively impact model training and downstream performance. The findings highlight the potential of small language models-which can be hosted on-premise in hospitals and integrated with EHRs-to improve real-world data collection and identify complex medical symptoms such as acute heart failure.",https://pubmed.ncbi.nlm.nih.gov/40541074/,急性心不全（AHF）を理解することは、電子健康記録（EHR）の構造化データではなく、非構造化されたテキストに多くの臨床的詳細が記録されるため、重要な課題のままです。この研究では、AHF入院を自動的に特定し、臨床ノートから正確なAHF関連の臨床情報を抽出するために、大規模な言語モデル（LLM）の使用を調査しました。フランスのナンテス大学病院からの臨床ノートに基づいて、汎用LLM QWEN2-7Bを使用し、フランスの生物医学的な前提条件モデルDrlongformerに対するパフォーマンスを評価しました。少数のショットやチェーンのプロンプトなどの監視された微調整およびコンテスト内の学習手法を調査し、モデルパフォーマンスに対するデータのボリュームと注釈特性の影響を分析するためのアブレーション研究を実施しました。我々の結果は、DrlongformerがAHF入院の分類において優れたパフォーマンスを達成し、F1スコアはQWEN2-7Bの0.80と比較して0.878であり、ほとんどの臨床情報を抽出する際に同様にアウトパフォームしたことを実証しました。ただし、QWEN2-7Bは、トレーニングセット（通常は体重とボディマス指数など）で微調整された場合、定量的結果を抽出する際のパフォーマンスが向上しました。私たちのアブレーション研究は、トレーニングで使用される臨床ノートの数がモデルのパフォーマンスに影響を与える重要な要因であることを明らかにしましたが、250のドキュメントの後に改善が層になっています。さらに、より長い注釈がモデルトレーニングとダウンストリームパフォーマンスに悪影響を与えることを観察しました。この調査結果は、病院でオンプレミスをホストし、EHRSと統合して実際のデータ収集を改善し、急性心不全などの複雑な医学的症状を特定することができる小さな言語モデルの可能性を強調しています。
40516963,LLM-Generated multiple choice practice quizzes for preclinical medical students.,2025,Advances in physiology education,"Camarata Troy, McCoy Lise, Rosenberg Robert, Temprine Grellinger Kelsey R, Brettschnieder Kylie, Berman Jonathan","Multiple choice questions (MCQs) are frequently used in medical education for assessment. Automated generation of MCQs in board-exam format could potentially save significant effort for faculty and generate a wider set of practice materials for student use. The goal of this study was to explore the feasibility of using ChatGPT by OpenAI to generate United States Medical Licensing Exam (USMLE)/Comprehensive Osteopathic Medical Licensing Examination (COMLEX-USA)-style practice quiz items as study aids. Researchers gave second-year medical students studying renal physiology access to a set of practice quizzes with ChatGPT-generated questions. The exam items generated were evaluated by independent experts for quality and adherence to the National Board of Medical Examiners (NBME)/National Board of Osteopathic Medical Examiners (NBOME) guidelines. Forty-nine percent of questions contained item writing flaws, and 22% contained factual or conceptual errors. However, 59/65 (91%) were categorized as a reasonable starting point for revision. These results demonstrate the feasibility of large language model (LLM)-generated practice questions in medical education but only when supervised by a subject matter expert with training in exam item writing.<b>NEW & NOTEWORTHY</b> Practice board exam questions generated by large language models can be made suitable for preclinical medical students by subject-matter experts.",https://pubmed.ncbi.nlm.nih.gov/40516963/,複数選択の質問（MCQ）は、評価のために医学教育で頻繁に使用されます。自動化されたMCQの発電は、ボードEXAM形式での形式で潜在的に大幅な努力を節約し、学生の使用のための幅広い練習資料を生成する可能性があります。この研究の目標は、OpenAIによるCHATGPTを使用して、米国の医療ライセンス試験（USMLE）/包括的なオステオパシー医療ライセンス試験（Comlex-USA）スタイルの練習クイズアイテムを研究エイドとして生成する可能性を調査することでした。研究者は、CHATGPTで生成された質問を含む一連の練習クイズへの腎生理学へのアクセスを研究する2年生の医学生を提供しました。生成された試験項目は、独立した専門家によって評価され、国立医療検査委員会（NBME）/国立オステオパシー医療検査委員会（NBOME）ガイドラインの遵守が評価されました。質問の49％にはアイテムの書き込みの欠陥が含まれており、22％には事実的または概念的なエラーが含まれていました。ただし、59/65（91％）は、改訂の合理的な出発点として分類されました。これらの結果は、医学教育における大規模な言語モデル（LLM）生成された練習問題の実現可能性を示していますが、試験項目の執筆のトレーニングを行う主題の専門家によって監督された場合にのみ。
